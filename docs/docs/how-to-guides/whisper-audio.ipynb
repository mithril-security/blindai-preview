{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlindAi Whisper Integration\n",
    "\n",
    "Speech recognition has become a crucial aspect of our everyday lives because to technological advancements, from virtual assistants like Siri and Alexa to transcribing services used in business and academics. Whisper is a state-of-the-art voice recognition API that takes advantage of the most recent developments in AI and machine learning to offer extremely accurate and effective transcription services.\n",
    "\n",
    "In this tutorial, we will explore the Whisper transcribe API and learn how to integrate it into our applications. We will cover the basics of authentication, setting up a project, and making API requests to transcribe audio files in various formats. Additionally, we will also explore some advanced features of the API, such as speaker diarization and custom language models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "Before we begin, you will need to install these Python libraries:\n",
    "\n",
    "- [blindai-preview-server] (https://pypi.org/project/blindai-preview-server/)\n",
    "- [blindai-preview] (https://pypi.org/project/blindai-preview/)\n",
    "- [gdown] (https://pypi.org/project/gdown/)\n",
    "- [Test Audio File](https://github.com/openai/whisper/raw/main/tests/jfk.flac)\n",
    "\n",
    "> NB: The `whisper` API hasn't yet been integrated into the `blindai-preview` Python library on PyPI. We will be using the local `blindai-preview` library for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting blindai-preview-server\n",
      "  Downloading blindai_preview_server-0.0.6-py3-none-manylinux2014_x86_64.whl (4.3 kB)\n",
      "Installing collected packages: blindai-preview-server\n",
      "Successfully installed blindai-preview-server-0.0.6\n",
      "Requirement already satisfied: gdown in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (4.6.4)\n",
      "Requirement already satisfied: six in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from gdown) (4.11.2)\n",
      "Requirement already satisfied: filelock in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: tqdm in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from requests[socks]->gdown) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/vscode/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "--2023-03-14 16:17:29--  https://www2.cs.uic.edu/~i101/SoundFiles/taunt.wav\n",
      "Resolving www2.cs.uic.edu (www2.cs.uic.edu)... 131.193.32.16\n",
      "Connecting to www2.cs.uic.edu (www2.cs.uic.edu)|131.193.32.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 91284 (89K) [audio/x-wav]\n",
      "Saving to: ‘taunt.wav’\n",
      "\n",
      "taunt.wav           100%[===================>]  89.14K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2023-03-14 16:17:29 (1.22 MB/s) - ‘taunt.wav’ saved [91284/91284]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install the BlindAi Preview Client Library using `poetry install`\n",
    "!pip install blindai-preview-server\n",
    "!pip install gdown\n",
    "\n",
    "# Download the taunt audio file from CS 101 at UIC and save it as `taunt.wav`\n",
    "!wget https://www2.cs.uic.edu/~i101/SoundFiles/taunt.wav -O taunt.wav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the BlindAi Preview Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading BlindAI server (version 0.0.6)...\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "The release might not be available yet for the current version. Exact error code: 404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mblindai_preview_server\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Start the server and return the PID of the process\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m bps \u001b[39m=\u001b[39m blindai_preview_server\u001b[39m.\u001b[39;49mstart()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages/blindai_preview_server/server.py:106\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m bastionlab_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd() \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/bin/blindai_server\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m bastion_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/mithril-security/blindai-preview/releases/download/v\u001b[39m\u001b[39m{\u001b[39;00mapp_version\u001b[39m}\u001b[39;00m\u001b[39m/blindai-\u001b[39m\u001b[39m{\u001b[39;00mapp_version\u001b[39m}\u001b[39;00m\u001b[39m-linux.zip\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 106\u001b[0m handle_download(\n\u001b[1;32m    107\u001b[0m     bastionlab_path,\n\u001b[1;32m    108\u001b[0m     bastion_url,\n\u001b[1;32m    109\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBlindAI server (version \u001b[39;49m\u001b[39m{\u001b[39;49;00mapp_version\u001b[39m}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    110\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mThe release might not be available yet for the current version\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m process \u001b[39m=\u001b[39m start_server(bastionlab_path)\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m process\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/blindai-preview-7Yaoi9am-py3.8/lib/python3.8/site-packages/blindai_preview_server/server.py:51\u001b[0m, in \u001b[0;36mhandle_download\u001b[0;34m(path_str, url, name, error_msg)\u001b[0m\n\u001b[1;32m     49\u001b[0m         extract_zip(response\u001b[39m.\u001b[39mread())\n\u001b[1;32m     50\u001b[0m     \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mraise\u001b[39;00m NotFoundError(\n\u001b[1;32m     52\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Exact error code: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(error_msg, e\u001b[39m.\u001b[39mcode)\n\u001b[1;32m     53\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m already installed\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name))\n",
      "\u001b[0;31mNotFoundError\u001b[0m: The release might not be available yet for the current version. Exact error code: 404"
     ]
    }
   ],
   "source": [
    "import blindai_preview_server\n",
    "\n",
    "# Start the server and return the PID of the process\n",
    "bps = blindai_preview_server.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will connect to the server set up. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the BlindAi Server\n",
    "\n",
    "We will now connect to the server set up. With the server running, we can now make API requests to the internal `whisper` API.\n",
    "We will be connecting to the server using the address \"localhost\".\n",
    "\n",
    "We will also be using the `simulation_mode` the client because we will using the Python wheel server which executes in simulation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blindai_preview\n",
    "\n",
    "# Create connection to BlindAi\n",
    "connection = blindai_preview.connect(\"localhost\", hazmat_http_on_untrusted_port=True, simulation_mode=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this connection object will be used to make API requests to the `whisper` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wqg1F0UkEdm3KB7n1BjfRLHnzKU2-G5S\n",
      "To: /workspaces/blindai-preview/docs/docs/how-to-guides/fake-whisper-model.onnx\n",
      "100%|██████████| 233M/233M [00:04<00:00, 56.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "transcript = blindai_preview.Audio.transcribe(\n",
    "    connection=connection,\n",
    "    model=\"tiny.en\",\n",
    "    file=\"taunt.wav\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transcript returned by the API will be stored in the `transcript` variable.\n",
    "\n",
    "And it contains the text of the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Now go away, or I shall taunt you a second timer!']\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutting Down the Server\n",
    "\n",
    "Now, we will shut down the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindai_preview_server.stop(bps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blindai-preview-7Yaoi9am-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
